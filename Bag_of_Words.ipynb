{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bag of Words.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixep7y0q61Yx"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6EU6gZZIwlw"
      },
      "source": [
        "paragraph = \"\"\"At SpaceX, Musk oversees the development of rockets and spacecraft for missions to Earth orbit and ultimately to other planets. In 2008, SpaceXâ€™s Falcon 9 rocket and Dragon spacecraft won the NASA contract to provide cargo transport to space. In 2012, SpaceX became the first commercial company to dock with the International Space Station and return cargo to Earth with the Dragon.\n",
        "\n",
        "At Tesla, Musk has overseen product development and design from the beginning, including the all-electric Tesla Roadster, Model S and Model X, and the rollout of Supercharger stations to keep the cars juiced up. (Some of the charging stations use solar energy systems from SolarCity, of which Musk is the non-executive chair.) Transitioning to a sustainable energy economy, in which electric vehicles play a pivotal role, has been one of his central interests for almost two decades. Before this, he co-founded PayPal and served as the company's chair and CEO.\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg98mdidI8Ro"
      },
      "source": [
        "#cleaning the texts\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XN7epweJhfW"
      },
      "source": [
        "ps = PorterStemmer()\n",
        "lem = WordNetLemmatizer()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3i01xFgJ_sD",
        "outputId": "3931a098-7c66-40c0-9c5e-eaa544edc89c"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDo_YC7mJ1Uz"
      },
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkuh03vfMm-3",
        "outputId": "bc188b88-ca9c-4fcd-dc92-0a754d4b449c"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbeFOHbVKEE-"
      },
      "source": [
        "#cleaning by using the stemming\n",
        "new_sent = [] #new sentences will be appended to this emptylist\n",
        "for i in range(len(sentences)):\n",
        "  cleaning = re.sub('[^a-zA-z]',' ',sentences[i]) #removing the ,.'/ these symbols from the sentences by using the regular expressions\n",
        "  cleaning = cleaning.lower() # making the small letters\n",
        "  cleaning = cleaning.split() #split functions makes the every sentence will be splitted the return value is a list\n",
        "  cleaning = [ps.stem(word) for word in cleaning if word not in set(stopwords.words('english'))] #aplling the stemming and removing the stop words like:  is, he, are etc; \n",
        "  cleaning = \" \".join(cleaning) #again combining the words to form into sentences\n",
        "  new_sent.append(cleaning) #appending into the empty list\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7ZFoA_AMrzV",
        "outputId": "4a83d5a1-6d65-43ca-dbea-8040fc2980f5"
      },
      "source": [
        "new_sent"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spacex musk overse develop rocket spacecraft mission earth orbit ultim planet',\n",
              " 'spacex falcon rocket dragon spacecraft nasa contract provid cargo transport space',\n",
              " 'spacex becam first commerci compani dock intern space station return cargo earth dragon',\n",
              " 'tesla musk overseen product develop design begin includ electr tesla roadster model model x rollout supercharg station keep car juic',\n",
              " 'charg station use solar energi system solarc musk non execut chair',\n",
              " 'transit sustain energi economi electr vehicl play pivot role one central interest almost two decad',\n",
              " 'co found paypal serv compani chair ceo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3rg9ilOlnC",
        "outputId": "10eeb411-c83b-4b2f-8646-9671d047e686"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxudXzxvNoU-"
      },
      "source": [
        "# cleaning by lemmatiation\n",
        "new_sent_lem = []\n",
        "for i in range(len(sentences)):\n",
        "  clean_lem = re.sub('[^a-zA-z]',' ',sentences[i])\n",
        "  clean_lem = clean_lem.lower()\n",
        "  clean_lem = clean_lem.split()\n",
        "  clean_lem = [lem.lemmatize(word) for word in clean_lem if word not in set(stopwords.words('english'))]\n",
        "  clean_lem = \" \".join(clean_lem)\n",
        "  new_sent_lem.append(clean_lem)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwEhRC51Oq-z",
        "outputId": "749c409f-0988-4b4c-8034-32ed58c7b6ee"
      },
      "source": [
        "new_sent_lem"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['spacex musk oversees development rocket spacecraft mission earth orbit ultimately planet',\n",
              " 'spacex falcon rocket dragon spacecraft nasa contract provide cargo transport space',\n",
              " 'spacex became first commercial company dock international space station return cargo earth dragon',\n",
              " 'tesla musk overseen product development design beginning including electric tesla roadster model model x rollout supercharger station keep car juiced',\n",
              " 'charging station use solar energy system solarcity musk non executive chair',\n",
              " 'transitioning sustainable energy economy electric vehicle play pivotal role one central interest almost two decade',\n",
              " 'co founded paypal served company chair ceo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iovHFhFyOu42"
      },
      "source": [
        "#creating the bag of words model\n",
        "#appliying the leammatization words to the bag of words model\n",
        "from sklearn.feature_extraction.text import CountVectorizer #countvectorizer responsible for the making the histogram and sorting in a decending order  and matching the features\n",
        "final_matrix = CountVectorizer().fit_transform(new_sent_lem).toarray() #fit transform is responsible for the below matrix creation"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KAVMWRrRyJO",
        "outputId": "1ea6b0f9-458b-402e-d014-0041fef29adf"
      },
      "source": [
        "final_matrix"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        1, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-GJR0JSSd2M"
      },
      "source": [
        "#bag of words model for stemming words but using the lemmatization is preferable for the sentimental analysis \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "final_mat_stem = CountVectorizer().fit_transform(new_sent).toarray()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9XG__aES4Up",
        "outputId": "6b3e650b-d464-431f-98bd-63d1aa84015c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_mat_stem"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        1, 0],\n",
              "       [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}